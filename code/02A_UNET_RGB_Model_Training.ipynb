{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3-ukkVMfx2ME"
   },
   "source": [
    "# **Identifying Nutrient Deficiencies in Satellite Farmland Imagery**\n",
    "## 02A: U-Net: RGB Channels Only\n",
    "\n",
    "I certainly did not conceive of the U-Net implementation in this notebook on my own. Credit is due to Harshall Lambda, and I'm citing his blog and U-Net notebook as sources of inspiration below:  \n",
    "[Towards Data Science article](https://towardsdatascience.com/understanding-semantic-segmentation-with-unet-6be4f42d4b47)  \n",
    "[U-Net Notebook (github)](https://github.com/hlamba28/UNET-TGS/blob/master/TGS%20UNET.ipynb)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Google Colab UNET Model Training Workbook (RGB channels only)\n",
    "\n",
    "This notebook was run **entirely in Google Colab** and may not work in Jupyter without some major modifications. It was run in Colab to take advantage of the GPU runtime.\n",
    "\n",
    "For this notebook to work in Colab, you'll also need the requisite image data. Details for retrieving, selecting, and uploading the requisite image data are contained in [Data Retrieval and Model Training Setup](../Data_Retrieval_and_Model_Training_Setup.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ajlV1oenxxbR",
    "outputId": "ba37dc62-bc0a-4fbf-8a9b-b8fcdc89d3cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# colab-specific tasks:\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lnYasDzBJfsC",
    "outputId": "92630d7c-55f5-45e6-eda0-cfbd32b6e8cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['features',\n",
       " 'labels',\n",
       " 'output',\n",
       " 'image_metatdata_with_clusters.csv',\n",
       " 'nir_features',\n",
       " 'features.zip',\n",
       " 'labels.zip',\n",
       " 'nir_features.zip']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "In order for this notebook to be runnable in Colab, you need\n",
    "to upload the following files into a directory, and point\n",
    "the `os.chdir()` call below to that directory.\n",
    "\n",
    "The output of the `os.listdir()` call should include \n",
    "the following files:\n",
    "\n",
    "[\n",
    "  'image_metadata_with_clusters.csv',\n",
    "  'features.zip',\n",
    "  'labels.zip',\n",
    "  'nir_features.zip',\n",
    "  'output'   ### OUTPUT directory should be blank\n",
    "]\n",
    "\n",
    "The `output` directory is where best model weights will be\n",
    "saved for later downloading.\n",
    "\"\"\"\n",
    "\n",
    "import os \n",
    "#make sure the path variable ends with a /\n",
    "gdrive_path = '### REPLACE WITH YOUR GOOGLE DRIVE FILEPATH ###'\n",
    "os.chdir(gdrive_path)\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "s6FDQGEbvYp9"
   },
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt, seaborn as sns\n",
    "%matplotlib inline\n",
    "np.random.seed(42)\n",
    "\n",
    "#some image processing modules:\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "#some tensorflow.keras modules:\n",
    "from tensorflow import math as tf\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n",
    "from tensorflow.keras.layers import Lambda, RepeatVector, Reshape\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import MaxPooling2D, GlobalMaxPool2D\n",
    "from tensorflow.keras.layers import concatenate, add\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "phu8FXIFwTY0"
   },
   "outputs": [],
   "source": [
    "#set parameters:\n",
    "im_width, im_height, input_channels = (128,128, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-mJ4mtvML6Z-"
   },
   "outputs": [],
   "source": [
    "#import metadata for image names:\n",
    "df = pd.read_csv('image_metadata_with_clusters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "SdsRlOKJwc2n"
   },
   "outputs": [],
   "source": [
    "#get image ids\n",
    "ids = [x+'.jpg' for x in df['image_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7bXH0L9Fwhi5",
    "outputId": "c3432d99-c579-4267-91eb-45df4b2c6c09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of images:  14712\n"
     ]
    }
   ],
   "source": [
    "print('No. of images: ', len(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yqO3ujxrL7Rc"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "NOTE:\n",
    "The commands below in Colab extract the images in the compressed\n",
    ".zip files to the *root* `/content` directory \n",
    "**of your CURRENT COLAB RUNTIME**.\n",
    "\n",
    "This is a **massive** performance improvement over keeping the\n",
    "uncompressed image files in Google Drive and loading each one\n",
    "into the Colab environment individually\n",
    "(I learned this from experience).\n",
    "\"\"\"\n",
    "\n",
    "#unzips images to /content in colab environment\n",
    "!unzip 'labels.zip' -d '/content'\n",
    "!unzip 'features.zip' -d '/content'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ZUP9S2SywjTY"
   },
   "outputs": [],
   "source": [
    "X = np.zeros((len(ids), im_height, im_width, input_channels), dtype=np.float32)\n",
    "y = np.zeros((len(ids), im_height, im_width, 1), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "XuZguht4wlJk"
   },
   "outputs": [],
   "source": [
    "for n, id_ in enumerate(ids):\n",
    "    #load images\n",
    "    x_img = img_to_array(load_img('/content/features/'+id_,color_mode='rgb'))\n",
    "    x_img = resize(x_img, (im_width,im_height,3), mode='constant',preserve_range=True)\n",
    "\n",
    "    #load masks:\n",
    "    mask = img_to_array(load_img('/content/labels/'+id_.replace('.jpg','.png'),color_mode='grayscale'))\n",
    "    mask = resize(mask,(im_width,im_height,1), mode='constant',preserve_range=True)\n",
    "    #save and scale them:\n",
    "    X[n] = x_img/255.0\n",
    "    y[n] = mask/255.0\n",
    "    \n",
    "del x_img\n",
    "del mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b6vwdHZAwphO",
    "outputId": "52dffa2d-c658-4d7e-c73d-46534d21a7b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X: (14712, 128, 128, 3)\n",
      "shape of y: (14712, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f'shape of X: {X.shape}')\n",
    "print(f'shape of y: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "qpu0TNb7wsP-"
   },
   "outputs": [],
   "source": [
    "test_size = 0.1 #90/10 train/val split\n",
    "split = int(len(X)*(1-test_size))\n",
    "X_train, X_valid = X[:split], X[split:]\n",
    "y_train, y_valid = y[:split], y[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sPsujdYiwt8B",
    "outputId": "a5a4f7ee-e44f-4ea5-82f2-577e6c46cfe2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13240, 128, 128, 3),\n",
       " (1472, 128, 128, 3),\n",
       " (13240, 128, 128, 1),\n",
       " (1472, 128, 128, 1))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_valid.shape, y_train.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "0yIiFLsyw3P6"
   },
   "outputs": [],
   "source": [
    "def conv2d_block(input_tensor, n_filters, kernel_size = 3, batchnorm = True):\n",
    "    \"\"\"Function to add 2 convolutional layers with the parameters passed to it\"\"\"\n",
    "    # first layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    # second layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "VltAaXfqw5Kf"
   },
   "outputs": [],
   "source": [
    "def get_unet(input_img, n_filters = 16, dropout = 0.1, batchnorm = True):\n",
    "    \"\"\"Function to define the UNET Model\"\"\"\n",
    "    # Contracting Path\n",
    "    c1 = conv2d_block(input_img, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    p1 = Dropout(dropout)(p1)\n",
    "    \n",
    "    c2 = conv2d_block(p1, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "    p2 = Dropout(dropout)(p2)\n",
    "    \n",
    "    c3 = conv2d_block(p2, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "    p3 = Dropout(dropout)(p3)\n",
    "    \n",
    "    c4 = conv2d_block(p3, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "    p4 = Dropout(dropout)(p4)\n",
    "    \n",
    "    c5 = conv2d_block(p4, n_filters = n_filters * 16, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    # Expansive Path\n",
    "    u6 = Conv2DTranspose(n_filters * 8, (3, 3), strides = (2, 2), padding = 'same')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    u6 = Dropout(dropout)(u6)\n",
    "    c6 = conv2d_block(u6, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    u7 = Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    u7 = Dropout(dropout)(u7)\n",
    "    c7 = conv2d_block(u7, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    u8 = Conv2DTranspose(n_filters * 2, (3, 3), strides = (2, 2), padding = 'same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    u8 = Dropout(dropout)(u8)\n",
    "    c8 = conv2d_block(u8, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    u9 = Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same')(c8)\n",
    "    u9 = concatenate([u9, c1])\n",
    "    u9 = Dropout(dropout)(u9)\n",
    "    c9 = conv2d_block(u9, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
    "    \n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "    model = Model(inputs=[input_img], outputs=[outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The keras implementation of the Jaccard Coeffient and Loss below were inspired by YouTuber [DigitalSreeni](https://www.youtube.com/channel/UC34rW-HtPJulxr5wp2Xa04w), specifically their video titled ['Using IoU (Jaccard) as loss function to train U-Net for semantic segmentation'](https://www.youtube.com/watch?v=BNPW1mYbgS4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "5IZAHuawbchY"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "#custom intersection over union loss function:\n",
    "def jaccard_coef(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        y_true : Matrix containing one-hot encoded class labels \n",
    "                 with the last axis being the number of classes.\n",
    "        y_pred : Matrix with same dimensions as y_true.\n",
    "    \"\"\"\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    \n",
    "    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n",
    "\n",
    "def jaccard_coef_loss(y_true,y_pred):\n",
    "    return -jaccard_coef(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "vGlWNJUrw6x9"
   },
   "outputs": [],
   "source": [
    "input_img = Input((im_height, im_width, input_channels), name='img')\n",
    "model = get_unet(input_img, n_filters=16, dropout=0.10, batchnorm=True)\n",
    "model.compile(optimizer=Adam(), loss=[jaccard_coef_loss], metrics=[jaccard_coef,\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "-X6imv5nw7-I",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "a6750651-c589-47e5-ed63-81919c77953d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " img (InputLayer)               [(None, 128, 128, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 128, 128, 16  448         ['img[0][0]']                    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 128, 128, 16  64         ['conv2d_1[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 128, 128, 16  0           ['batch_normalization_1[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 64, 64, 16)   0           ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 64, 64, 16)   0           ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 64, 64, 32)   4640        ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 64, 64, 32)  128         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 64, 64, 32)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 32)  0           ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 32, 32, 32)   0           ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 32, 32, 64)   18496       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 32, 32, 64)  256         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 32, 32, 64)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 64)  0           ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 16, 16, 64)   0           ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 16, 16, 128)  73856       ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 16, 16, 128)  512        ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 16, 16, 128)  0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 128)   0           ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 8, 8, 128)    0           ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 8, 8, 256)    295168      ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 8, 8, 256)   1024        ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 8, 8, 256)    0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 16, 16, 128)  295040     ['activation_9[0][0]']           \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 16, 16, 256)  0           ['conv2d_transpose[0][0]',       \n",
      "                                                                  'activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 16, 16, 256)  0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 16, 16, 128)  295040      ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 16, 16, 128)  512        ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 16, 16, 128)  0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 32, 32, 64)  73792       ['activation_11[0][0]']          \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 32, 32, 128)  0           ['conv2d_transpose_1[0][0]',     \n",
      "                                                                  'activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 32, 32, 128)  0           ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 32, 32, 64)   73792       ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 32, 32, 64)  256         ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 32, 32, 64)   0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 64, 64, 32)  18464       ['activation_13[0][0]']          \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 64, 64, 64)   0           ['conv2d_transpose_2[0][0]',     \n",
      "                                                                  'activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 64, 64, 64)   0           ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 64, 64, 32)   18464       ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 64, 64, 32)  128         ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 64, 64, 32)   0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2DTran  (None, 128, 128, 16  4624       ['activation_15[0][0]']          \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 128, 128, 32  0           ['conv2d_transpose_3[0][0]',     \n",
      "                                )                                 'activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 128, 128, 32  0           ['concatenate_3[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 128, 128, 16  4624        ['dropout_7[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 128, 128, 16  64         ['conv2d_17[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 128, 128, 16  0           ['batch_normalization_17[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 128, 128, 1)  17          ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,179,409\n",
      "Trainable params: 1,177,937\n",
      "Non-trainable params: 1,472\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "5EZL-es6w9iU"
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    ReduceLROnPlateau(factor=0.1, patience=15, min_lr=0.00001, verbose=1),\n",
    "    ModelCheckpoint('output/rgb_nutrient_deficiency_identifier_JACCARD.h5', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "XwO9jebZw-qC",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "f8409d6b-74b4-4090-c12a-e059dc1092e7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "414/414 [==============================] - ETA: 0s - loss: -0.3334 - jaccard_coef: 0.3335 - accuracy: 0.3884\n",
      "Epoch 00001: val_loss improved from inf to -0.37667, saving model to output/rgb_nutrient_deficiency_identifier_JACCARD.h5\n",
      "414/414 [==============================] - 29s 43ms/step - loss: -0.3334 - jaccard_coef: 0.3335 - accuracy: 0.3884 - val_loss: -0.3767 - val_jaccard_coef: 0.3767 - val_accuracy: 0.3921 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.3607 - jaccard_coef: 0.3607 - accuracy: 0.3968\n",
      "Epoch 00002: val_loss improved from -0.37667 to -0.38653, saving model to output/rgb_nutrient_deficiency_identifier_JACCARD.h5\n",
      "414/414 [==============================] - 17s 42ms/step - loss: -0.3606 - jaccard_coef: 0.3605 - accuracy: 0.3967 - val_loss: -0.3865 - val_jaccard_coef: 0.3865 - val_accuracy: 0.4180 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.3647 - jaccard_coef: 0.3647 - accuracy: 0.4018\n",
      "Epoch 00003: val_loss did not improve from -0.38653\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.3646 - jaccard_coef: 0.3645 - accuracy: 0.4017 - val_loss: -0.3836 - val_jaccard_coef: 0.3836 - val_accuracy: 0.3630 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.3673 - jaccard_coef: 0.3673 - accuracy: 0.4160\n",
      "Epoch 00004: val_loss improved from -0.38653 to -0.39192, saving model to output/rgb_nutrient_deficiency_identifier_JACCARD.h5\n",
      "414/414 [==============================] - 17s 41ms/step - loss: -0.3671 - jaccard_coef: 0.3670 - accuracy: 0.4158 - val_loss: -0.3919 - val_jaccard_coef: 0.3919 - val_accuracy: 0.4005 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.3694 - jaccard_coef: 0.3694 - accuracy: 0.4240\n",
      "Epoch 00005: val_loss did not improve from -0.39192\n",
      "414/414 [==============================] - 17s 41ms/step - loss: -0.3694 - jaccard_coef: 0.3694 - accuracy: 0.4240 - val_loss: -0.3891 - val_jaccard_coef: 0.3891 - val_accuracy: 0.4297 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.3727 - jaccard_coef: 0.3727 - accuracy: 0.4443\n",
      "Epoch 00006: val_loss improved from -0.39192 to -0.39685, saving model to output/rgb_nutrient_deficiency_identifier_JACCARD.h5\n",
      "414/414 [==============================] - 17s 41ms/step - loss: -0.3727 - jaccard_coef: 0.3727 - accuracy: 0.4444 - val_loss: -0.3969 - val_jaccard_coef: 0.3969 - val_accuracy: 0.4671 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.3757 - jaccard_coef: 0.3757 - accuracy: 0.4536\n",
      "Epoch 00007: val_loss did not improve from -0.39685\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.3759 - jaccard_coef: 0.3760 - accuracy: 0.4538 - val_loss: -0.3706 - val_jaccard_coef: 0.3706 - val_accuracy: 0.5498 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.3766 - jaccard_coef: 0.3766 - accuracy: 0.4619\n",
      "Epoch 00008: val_loss did not improve from -0.39685\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.3768 - jaccard_coef: 0.3769 - accuracy: 0.4621 - val_loss: -0.3911 - val_jaccard_coef: 0.3911 - val_accuracy: 0.4856 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.3792 - jaccard_coef: 0.3792 - accuracy: 0.4749\n",
      "Epoch 00009: val_loss did not improve from -0.39685\n",
      "414/414 [==============================] - 17s 41ms/step - loss: -0.3790 - jaccard_coef: 0.3789 - accuracy: 0.4747 - val_loss: -0.3904 - val_jaccard_coef: 0.3904 - val_accuracy: 0.4866 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.3814 - jaccard_coef: 0.3814 - accuracy: 0.4853\n",
      "Epoch 00010: val_loss improved from -0.39685 to -0.39871, saving model to output/rgb_nutrient_deficiency_identifier_JACCARD.h5\n",
      "414/414 [==============================] - 17s 41ms/step - loss: -0.3815 - jaccard_coef: 0.3816 - accuracy: 0.4854 - val_loss: -0.3987 - val_jaccard_coef: 0.3987 - val_accuracy: 0.4945 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.3840 - jaccard_coef: 0.3840 - accuracy: 0.4969\n",
      "Epoch 00011: val_loss did not improve from -0.39871\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.3841 - jaccard_coef: 0.3841 - accuracy: 0.4970 - val_loss: -0.3821 - val_jaccard_coef: 0.3821 - val_accuracy: 0.5292 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.3862 - jaccard_coef: 0.3862 - accuracy: 0.5025\n",
      "Epoch 00012: val_loss did not improve from -0.39871\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.3860 - jaccard_coef: 0.3860 - accuracy: 0.5024 - val_loss: -0.3828 - val_jaccard_coef: 0.3828 - val_accuracy: 0.5533 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "414/414 [==============================] - ETA: 0s - loss: -0.3892 - jaccard_coef: 0.3892 - accuracy: 0.5131\n",
      "Epoch 00013: val_loss improved from -0.39871 to -0.40480, saving model to output/rgb_nutrient_deficiency_identifier_JACCARD.h5\n",
      "414/414 [==============================] - 18s 42ms/step - loss: -0.3892 - jaccard_coef: 0.3892 - accuracy: 0.5131 - val_loss: -0.4048 - val_jaccard_coef: 0.4048 - val_accuracy: 0.5117 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.3908 - jaccard_coef: 0.3908 - accuracy: 0.5178\n",
      "Epoch 00014: val_loss did not improve from -0.40480\n",
      "414/414 [==============================] - 17s 41ms/step - loss: -0.3909 - jaccard_coef: 0.3909 - accuracy: 0.5179 - val_loss: -0.3979 - val_jaccard_coef: 0.3979 - val_accuracy: 0.5381 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.3937 - jaccard_coef: 0.3937 - accuracy: 0.5292\n",
      "Epoch 00015: val_loss did not improve from -0.40480\n",
      "414/414 [==============================] - 18s 43ms/step - loss: -0.3938 - jaccard_coef: 0.3938 - accuracy: 0.5293 - val_loss: -0.3976 - val_jaccard_coef: 0.3976 - val_accuracy: 0.5449 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "414/414 [==============================] - ETA: 0s - loss: -0.3962 - jaccard_coef: 0.3961 - accuracy: 0.5318\n",
      "Epoch 00016: val_loss improved from -0.40480 to -0.40752, saving model to output/rgb_nutrient_deficiency_identifier_JACCARD.h5\n",
      "414/414 [==============================] - 18s 42ms/step - loss: -0.3962 - jaccard_coef: 0.3961 - accuracy: 0.5318 - val_loss: -0.4075 - val_jaccard_coef: 0.4075 - val_accuracy: 0.5212 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.3980 - jaccard_coef: 0.3980 - accuracy: 0.5379\n",
      "Epoch 00017: val_loss did not improve from -0.40752\n",
      "414/414 [==============================] - 18s 42ms/step - loss: -0.3979 - jaccard_coef: 0.3979 - accuracy: 0.5379 - val_loss: -0.3982 - val_jaccard_coef: 0.3982 - val_accuracy: 0.5326 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "414/414 [==============================] - ETA: 0s - loss: -0.3995 - jaccard_coef: 0.3995 - accuracy: 0.5435\n",
      "Epoch 00018: val_loss did not improve from -0.40752\n",
      "414/414 [==============================] - 17s 42ms/step - loss: -0.3995 - jaccard_coef: 0.3995 - accuracy: 0.5435 - val_loss: -0.3953 - val_jaccard_coef: 0.3953 - val_accuracy: 0.5215 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "414/414 [==============================] - ETA: 0s - loss: -0.3994 - jaccard_coef: 0.3995 - accuracy: 0.5379\n",
      "Epoch 00019: val_loss did not improve from -0.40752\n",
      "414/414 [==============================] - 17s 41ms/step - loss: -0.3994 - jaccard_coef: 0.3995 - accuracy: 0.5379 - val_loss: -0.4000 - val_jaccard_coef: 0.4000 - val_accuracy: 0.5511 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4005 - jaccard_coef: 0.4005 - accuracy: 0.5451\n",
      "Epoch 00020: val_loss did not improve from -0.40752\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4004 - jaccard_coef: 0.4004 - accuracy: 0.5450 - val_loss: -0.4013 - val_jaccard_coef: 0.4013 - val_accuracy: 0.5657 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4038 - jaccard_coef: 0.4038 - accuracy: 0.5490\n",
      "Epoch 00021: val_loss did not improve from -0.40752\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4037 - jaccard_coef: 0.4036 - accuracy: 0.5489 - val_loss: -0.3992 - val_jaccard_coef: 0.3992 - val_accuracy: 0.5914 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4050 - jaccard_coef: 0.4050 - accuracy: 0.5566\n",
      "Epoch 00022: val_loss improved from -0.40752 to -0.41168, saving model to output/rgb_nutrient_deficiency_identifier_JACCARD.h5\n",
      "414/414 [==============================] - 17s 41ms/step - loss: -0.4049 - jaccard_coef: 0.4049 - accuracy: 0.5566 - val_loss: -0.4117 - val_jaccard_coef: 0.4117 - val_accuracy: 0.5460 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4064 - jaccard_coef: 0.4064 - accuracy: 0.5566\n",
      "Epoch 00023: val_loss did not improve from -0.41168\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4062 - jaccard_coef: 0.4062 - accuracy: 0.5565 - val_loss: -0.3459 - val_jaccard_coef: 0.3459 - val_accuracy: 0.6240 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4074 - jaccard_coef: 0.4074 - accuracy: 0.5635\n",
      "Epoch 00024: val_loss did not improve from -0.41168\n",
      "414/414 [==============================] - 17s 41ms/step - loss: -0.4073 - jaccard_coef: 0.4072 - accuracy: 0.5634 - val_loss: -0.3709 - val_jaccard_coef: 0.3709 - val_accuracy: 0.6140 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "414/414 [==============================] - ETA: 0s - loss: -0.4105 - jaccard_coef: 0.4105 - accuracy: 0.5672\n",
      "Epoch 00025: val_loss did not improve from -0.41168\n",
      "414/414 [==============================] - 17s 41ms/step - loss: -0.4105 - jaccard_coef: 0.4105 - accuracy: 0.5672 - val_loss: -0.3975 - val_jaccard_coef: 0.3975 - val_accuracy: 0.5024 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4091 - jaccard_coef: 0.4091 - accuracy: 0.5662\n",
      "Epoch 00026: val_loss did not improve from -0.41168\n",
      "414/414 [==============================] - 17s 41ms/step - loss: -0.4093 - jaccard_coef: 0.4093 - accuracy: 0.5662 - val_loss: -0.4064 - val_jaccard_coef: 0.4064 - val_accuracy: 0.5675 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4119 - jaccard_coef: 0.4119 - accuracy: 0.5683\n",
      "Epoch 00027: val_loss did not improve from -0.41168\n",
      "414/414 [==============================] - 17s 41ms/step - loss: -0.4120 - jaccard_coef: 0.4120 - accuracy: 0.5683 - val_loss: -0.4016 - val_jaccard_coef: 0.4016 - val_accuracy: 0.5617 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4145 - jaccard_coef: 0.4145 - accuracy: 0.5742\n",
      "Epoch 00028: val_loss did not improve from -0.41168\n",
      "414/414 [==============================] - 17s 41ms/step - loss: -0.4146 - jaccard_coef: 0.4146 - accuracy: 0.5742 - val_loss: -0.4040 - val_jaccard_coef: 0.4040 - val_accuracy: 0.5586 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4155 - jaccard_coef: 0.4155 - accuracy: 0.5779\n",
      "Epoch 00029: val_loss did not improve from -0.41168\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4155 - jaccard_coef: 0.4155 - accuracy: 0.5780 - val_loss: -0.3959 - val_jaccard_coef: 0.3959 - val_accuracy: 0.5577 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4162 - jaccard_coef: 0.4162 - accuracy: 0.5798\n",
      "Epoch 00030: val_loss improved from -0.41168 to -0.41524, saving model to output/rgb_nutrient_deficiency_identifier_JACCARD.h5\n",
      "414/414 [==============================] - 17s 41ms/step - loss: -0.4161 - jaccard_coef: 0.4161 - accuracy: 0.5798 - val_loss: -0.4152 - val_jaccard_coef: 0.4152 - val_accuracy: 0.5680 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4174 - jaccard_coef: 0.4174 - accuracy: 0.5781\n",
      "Epoch 00031: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4173 - jaccard_coef: 0.4173 - accuracy: 0.5780 - val_loss: -0.3849 - val_jaccard_coef: 0.3849 - val_accuracy: 0.5946 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4195 - jaccard_coef: 0.4195 - accuracy: 0.5859\n",
      "Epoch 00032: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4194 - jaccard_coef: 0.4194 - accuracy: 0.5858 - val_loss: -0.3925 - val_jaccard_coef: 0.3925 - val_accuracy: 0.5942 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4217 - jaccard_coef: 0.4217 - accuracy: 0.5872\n",
      "Epoch 00033: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4216 - jaccard_coef: 0.4216 - accuracy: 0.5872 - val_loss: -0.4011 - val_jaccard_coef: 0.4011 - val_accuracy: 0.5906 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4226 - jaccard_coef: 0.4226 - accuracy: 0.5890\n",
      "Epoch 00034: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4225 - jaccard_coef: 0.4225 - accuracy: 0.5890 - val_loss: -0.4068 - val_jaccard_coef: 0.4068 - val_accuracy: 0.5382 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4228 - jaccard_coef: 0.4228 - accuracy: 0.5887\n",
      "Epoch 00035: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4228 - jaccard_coef: 0.4228 - accuracy: 0.5886 - val_loss: -0.3779 - val_jaccard_coef: 0.3779 - val_accuracy: 0.6132 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4254 - jaccard_coef: 0.4254 - accuracy: 0.5921\n",
      "Epoch 00036: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4255 - jaccard_coef: 0.4256 - accuracy: 0.5922 - val_loss: -0.4000 - val_jaccard_coef: 0.4000 - val_accuracy: 0.5170 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4269 - jaccard_coef: 0.4269 - accuracy: 0.5978\n",
      "Epoch 00037: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4266 - jaccard_coef: 0.4265 - accuracy: 0.5976 - val_loss: -0.4106 - val_jaccard_coef: 0.4106 - val_accuracy: 0.5726 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4281 - jaccard_coef: 0.4281 - accuracy: 0.5984\n",
      "Epoch 00038: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4282 - jaccard_coef: 0.4282 - accuracy: 0.5984 - val_loss: -0.4037 - val_jaccard_coef: 0.4037 - val_accuracy: 0.5770 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4288 - jaccard_coef: 0.4288 - accuracy: 0.6005\n",
      "Epoch 00039: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4288 - jaccard_coef: 0.4287 - accuracy: 0.6005 - val_loss: -0.3822 - val_jaccard_coef: 0.3822 - val_accuracy: 0.6196 - lr: 0.0010\n",
      "Epoch 40/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4306 - jaccard_coef: 0.4306 - accuracy: 0.6030\n",
      "Epoch 00040: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4306 - jaccard_coef: 0.4306 - accuracy: 0.6030 - val_loss: -0.4071 - val_jaccard_coef: 0.4071 - val_accuracy: 0.5664 - lr: 0.0010\n",
      "Epoch 41/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4320 - jaccard_coef: 0.4320 - accuracy: 0.6050\n",
      "Epoch 00041: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4318 - jaccard_coef: 0.4318 - accuracy: 0.6049 - val_loss: -0.3861 - val_jaccard_coef: 0.3861 - val_accuracy: 0.6027 - lr: 0.0010\n",
      "Epoch 42/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4346 - jaccard_coef: 0.4346 - accuracy: 0.6079\n",
      "Epoch 00042: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4346 - jaccard_coef: 0.4346 - accuracy: 0.6079 - val_loss: -0.4028 - val_jaccard_coef: 0.4028 - val_accuracy: 0.5873 - lr: 0.0010\n",
      "Epoch 43/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4348 - jaccard_coef: 0.4348 - accuracy: 0.6120\n",
      "Epoch 00043: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4349 - jaccard_coef: 0.4349 - accuracy: 0.6120 - val_loss: -0.3954 - val_jaccard_coef: 0.3954 - val_accuracy: 0.5594 - lr: 0.0010\n",
      "Epoch 44/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4365 - jaccard_coef: 0.4365 - accuracy: 0.6126\n",
      "Epoch 00044: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4364 - jaccard_coef: 0.4364 - accuracy: 0.6125 - val_loss: -0.4052 - val_jaccard_coef: 0.4052 - val_accuracy: 0.5406 - lr: 0.0010\n",
      "Epoch 45/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4391 - jaccard_coef: 0.4391 - accuracy: 0.6171\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00045: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4389 - jaccard_coef: 0.4388 - accuracy: 0.6170 - val_loss: -0.3969 - val_jaccard_coef: 0.3969 - val_accuracy: 0.5873 - lr: 0.0010\n",
      "Epoch 46/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4494 - jaccard_coef: 0.4494 - accuracy: 0.6273\n",
      "Epoch 00046: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4495 - jaccard_coef: 0.4495 - accuracy: 0.6274 - val_loss: -0.4095 - val_jaccard_coef: 0.4095 - val_accuracy: 0.6084 - lr: 1.0000e-04\n",
      "Epoch 47/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4551 - jaccard_coef: 0.4551 - accuracy: 0.6363\n",
      "Epoch 00047: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4550 - jaccard_coef: 0.4550 - accuracy: 0.6362 - val_loss: -0.4050 - val_jaccard_coef: 0.4050 - val_accuracy: 0.6113 - lr: 1.0000e-04\n",
      "Epoch 48/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4541 - jaccard_coef: 0.4541 - accuracy: 0.6381\n",
      "Epoch 00048: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4541 - jaccard_coef: 0.4542 - accuracy: 0.6381 - val_loss: -0.4003 - val_jaccard_coef: 0.4003 - val_accuracy: 0.6234 - lr: 1.0000e-04\n",
      "Epoch 49/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4558 - jaccard_coef: 0.4558 - accuracy: 0.6388\n",
      "Epoch 00049: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4558 - jaccard_coef: 0.4559 - accuracy: 0.6389 - val_loss: -0.4106 - val_jaccard_coef: 0.4106 - val_accuracy: 0.6093 - lr: 1.0000e-04\n",
      "Epoch 50/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4562 - jaccard_coef: 0.4562 - accuracy: 0.6391\n",
      "Epoch 00050: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4563 - jaccard_coef: 0.4563 - accuracy: 0.6392 - val_loss: -0.4117 - val_jaccard_coef: 0.4117 - val_accuracy: 0.6141 - lr: 1.0000e-04\n",
      "Epoch 51/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4565 - jaccard_coef: 0.4565 - accuracy: 0.6397\n",
      "Epoch 00051: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4566 - jaccard_coef: 0.4566 - accuracy: 0.6397 - val_loss: -0.4106 - val_jaccard_coef: 0.4106 - val_accuracy: 0.6174 - lr: 1.0000e-04\n",
      "Epoch 52/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4580 - jaccard_coef: 0.4580 - accuracy: 0.6425\n",
      "Epoch 00052: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4579 - jaccard_coef: 0.4579 - accuracy: 0.6425 - val_loss: -0.4075 - val_jaccard_coef: 0.4075 - val_accuracy: 0.6164 - lr: 1.0000e-04\n",
      "Epoch 53/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4590 - jaccard_coef: 0.4590 - accuracy: 0.6437\n",
      "Epoch 00053: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4589 - jaccard_coef: 0.4589 - accuracy: 0.6437 - val_loss: -0.4057 - val_jaccard_coef: 0.4057 - val_accuracy: 0.6140 - lr: 1.0000e-04\n",
      "Epoch 54/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4593 - jaccard_coef: 0.4593 - accuracy: 0.6453\n",
      "Epoch 00054: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4592 - jaccard_coef: 0.4592 - accuracy: 0.6453 - val_loss: -0.4033 - val_jaccard_coef: 0.4033 - val_accuracy: 0.6126 - lr: 1.0000e-04\n",
      "Epoch 55/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4600 - jaccard_coef: 0.4600 - accuracy: 0.6457\n",
      "Epoch 00055: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4603 - jaccard_coef: 0.4603 - accuracy: 0.6459 - val_loss: -0.4090 - val_jaccard_coef: 0.4090 - val_accuracy: 0.6160 - lr: 1.0000e-04\n",
      "Epoch 56/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4601 - jaccard_coef: 0.4601 - accuracy: 0.6449\n",
      "Epoch 00056: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4599 - jaccard_coef: 0.4598 - accuracy: 0.6447 - val_loss: -0.4051 - val_jaccard_coef: 0.4051 - val_accuracy: 0.6102 - lr: 1.0000e-04\n",
      "Epoch 57/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4616 - jaccard_coef: 0.4616 - accuracy: 0.6476\n",
      "Epoch 00057: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4615 - jaccard_coef: 0.4615 - accuracy: 0.6476 - val_loss: -0.4114 - val_jaccard_coef: 0.4114 - val_accuracy: 0.6198 - lr: 1.0000e-04\n",
      "Epoch 58/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4612 - jaccard_coef: 0.4612 - accuracy: 0.6468\n",
      "Epoch 00058: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4613 - jaccard_coef: 0.4613 - accuracy: 0.6469 - val_loss: -0.4069 - val_jaccard_coef: 0.4069 - val_accuracy: 0.6151 - lr: 1.0000e-04\n",
      "Epoch 59/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4624 - jaccard_coef: 0.4624 - accuracy: 0.6480\n",
      "Epoch 00059: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4624 - jaccard_coef: 0.4624 - accuracy: 0.6480 - val_loss: -0.4081 - val_jaccard_coef: 0.4081 - val_accuracy: 0.6154 - lr: 1.0000e-04\n",
      "Epoch 60/100\n",
      "414/414 [==============================] - ETA: 0s - loss: -0.4632 - jaccard_coef: 0.4632 - accuracy: 0.6487\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00060: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4632 - jaccard_coef: 0.4632 - accuracy: 0.6487 - val_loss: -0.4006 - val_jaccard_coef: 0.4006 - val_accuracy: 0.6263 - lr: 1.0000e-04\n",
      "Epoch 61/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4633 - jaccard_coef: 0.4633 - accuracy: 0.6479\n",
      "Epoch 00061: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4633 - jaccard_coef: 0.4633 - accuracy: 0.6479 - val_loss: -0.4056 - val_jaccard_coef: 0.4056 - val_accuracy: 0.6202 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4639 - jaccard_coef: 0.4639 - accuracy: 0.6492\n",
      "Epoch 00062: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4638 - jaccard_coef: 0.4637 - accuracy: 0.6491 - val_loss: -0.4038 - val_jaccard_coef: 0.4038 - val_accuracy: 0.6210 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4649 - jaccard_coef: 0.4649 - accuracy: 0.6507\n",
      "Epoch 00063: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4648 - jaccard_coef: 0.4648 - accuracy: 0.6507 - val_loss: -0.4047 - val_jaccard_coef: 0.4047 - val_accuracy: 0.6223 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4642 - jaccard_coef: 0.4642 - accuracy: 0.6500\n",
      "Epoch 00064: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4643 - jaccard_coef: 0.4643 - accuracy: 0.6499 - val_loss: -0.4069 - val_jaccard_coef: 0.4069 - val_accuracy: 0.6207 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4640 - jaccard_coef: 0.4640 - accuracy: 0.6500\n",
      "Epoch 00065: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4641 - jaccard_coef: 0.4641 - accuracy: 0.6501 - val_loss: -0.4067 - val_jaccard_coef: 0.4067 - val_accuracy: 0.6204 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4644 - jaccard_coef: 0.4644 - accuracy: 0.6505\n",
      "Epoch 00066: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4644 - jaccard_coef: 0.4644 - accuracy: 0.6505 - val_loss: -0.4052 - val_jaccard_coef: 0.4052 - val_accuracy: 0.6216 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4657 - jaccard_coef: 0.4657 - accuracy: 0.6524\n",
      "Epoch 00067: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4658 - jaccard_coef: 0.4658 - accuracy: 0.6524 - val_loss: -0.4056 - val_jaccard_coef: 0.4056 - val_accuracy: 0.6211 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4635 - jaccard_coef: 0.4635 - accuracy: 0.6501\n",
      "Epoch 00068: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4636 - jaccard_coef: 0.4637 - accuracy: 0.6501 - val_loss: -0.4053 - val_jaccard_coef: 0.4053 - val_accuracy: 0.6222 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4640 - jaccard_coef: 0.4640 - accuracy: 0.6494\n",
      "Epoch 00069: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4640 - jaccard_coef: 0.4640 - accuracy: 0.6495 - val_loss: -0.4078 - val_jaccard_coef: 0.4078 - val_accuracy: 0.6191 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4659 - jaccard_coef: 0.4659 - accuracy: 0.6519\n",
      "Epoch 00070: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4660 - jaccard_coef: 0.4660 - accuracy: 0.6519 - val_loss: -0.4068 - val_jaccard_coef: 0.4068 - val_accuracy: 0.6201 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4640 - jaccard_coef: 0.4640 - accuracy: 0.6505\n",
      "Epoch 00071: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4643 - jaccard_coef: 0.4644 - accuracy: 0.6506 - val_loss: -0.4068 - val_jaccard_coef: 0.4068 - val_accuracy: 0.6216 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4648 - jaccard_coef: 0.4648 - accuracy: 0.6510\n",
      "Epoch 00072: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4648 - jaccard_coef: 0.4648 - accuracy: 0.6511 - val_loss: -0.4052 - val_jaccard_coef: 0.4052 - val_accuracy: 0.6209 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4644 - jaccard_coef: 0.4644 - accuracy: 0.6507\n",
      "Epoch 00073: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4645 - jaccard_coef: 0.4645 - accuracy: 0.6507 - val_loss: -0.4063 - val_jaccard_coef: 0.4063 - val_accuracy: 0.6198 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4642 - jaccard_coef: 0.4642 - accuracy: 0.6502\n",
      "Epoch 00074: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4641 - jaccard_coef: 0.4641 - accuracy: 0.6502 - val_loss: -0.4066 - val_jaccard_coef: 0.4066 - val_accuracy: 0.6212 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4642 - jaccard_coef: 0.4642 - accuracy: 0.6510\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "\n",
      "Epoch 00075: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4642 - jaccard_coef: 0.4642 - accuracy: 0.6510 - val_loss: -0.4073 - val_jaccard_coef: 0.4073 - val_accuracy: 0.6196 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4662 - jaccard_coef: 0.4662 - accuracy: 0.6523\n",
      "Epoch 00076: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4663 - jaccard_coef: 0.4663 - accuracy: 0.6523 - val_loss: -0.4059 - val_jaccard_coef: 0.4059 - val_accuracy: 0.6200 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4649 - jaccard_coef: 0.4649 - accuracy: 0.6516\n",
      "Epoch 00077: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4649 - jaccard_coef: 0.4649 - accuracy: 0.6516 - val_loss: -0.4079 - val_jaccard_coef: 0.4079 - val_accuracy: 0.6206 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4660 - jaccard_coef: 0.4660 - accuracy: 0.6522\n",
      "Epoch 00078: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4660 - jaccard_coef: 0.4661 - accuracy: 0.6522 - val_loss: -0.4065 - val_jaccard_coef: 0.4065 - val_accuracy: 0.6210 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4658 - jaccard_coef: 0.4658 - accuracy: 0.6524\n",
      "Epoch 00079: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4657 - jaccard_coef: 0.4656 - accuracy: 0.6523 - val_loss: -0.4075 - val_jaccard_coef: 0.4075 - val_accuracy: 0.6201 - lr: 1.0000e-05\n",
      "Epoch 80/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4659 - jaccard_coef: 0.4659 - accuracy: 0.6533\n",
      "Epoch 00080: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 41ms/step - loss: -0.4660 - jaccard_coef: 0.4661 - accuracy: 0.6533 - val_loss: -0.4058 - val_jaccard_coef: 0.4058 - val_accuracy: 0.6222 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4662 - jaccard_coef: 0.4662 - accuracy: 0.6530\n",
      "Epoch 00081: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4662 - jaccard_coef: 0.4663 - accuracy: 0.6531 - val_loss: -0.4077 - val_jaccard_coef: 0.4077 - val_accuracy: 0.6205 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4664 - jaccard_coef: 0.4664 - accuracy: 0.6528\n",
      "Epoch 00082: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4665 - jaccard_coef: 0.4665 - accuracy: 0.6529 - val_loss: -0.4065 - val_jaccard_coef: 0.4065 - val_accuracy: 0.6215 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4654 - jaccard_coef: 0.4654 - accuracy: 0.6520\n",
      "Epoch 00083: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4653 - jaccard_coef: 0.4653 - accuracy: 0.6519 - val_loss: -0.4092 - val_jaccard_coef: 0.4092 - val_accuracy: 0.6195 - lr: 1.0000e-05\n",
      "Epoch 84/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4655 - jaccard_coef: 0.4655 - accuracy: 0.6521\n",
      "Epoch 00084: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4654 - jaccard_coef: 0.4654 - accuracy: 0.6521 - val_loss: -0.4052 - val_jaccard_coef: 0.4052 - val_accuracy: 0.6209 - lr: 1.0000e-05\n",
      "Epoch 85/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4672 - jaccard_coef: 0.4672 - accuracy: 0.6539\n",
      "Epoch 00085: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4672 - jaccard_coef: 0.4671 - accuracy: 0.6539 - val_loss: -0.4080 - val_jaccard_coef: 0.4080 - val_accuracy: 0.6208 - lr: 1.0000e-05\n",
      "Epoch 86/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4666 - jaccard_coef: 0.4666 - accuracy: 0.6532\n",
      "Epoch 00086: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4665 - jaccard_coef: 0.4664 - accuracy: 0.6532 - val_loss: -0.4084 - val_jaccard_coef: 0.4084 - val_accuracy: 0.6204 - lr: 1.0000e-05\n",
      "Epoch 87/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4665 - jaccard_coef: 0.4665 - accuracy: 0.6529\n",
      "Epoch 00087: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4664 - jaccard_coef: 0.4664 - accuracy: 0.6529 - val_loss: -0.4085 - val_jaccard_coef: 0.4085 - val_accuracy: 0.6199 - lr: 1.0000e-05\n",
      "Epoch 88/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4662 - jaccard_coef: 0.4662 - accuracy: 0.6531\n",
      "Epoch 00088: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4662 - jaccard_coef: 0.4662 - accuracy: 0.6531 - val_loss: -0.4063 - val_jaccard_coef: 0.4063 - val_accuracy: 0.6220 - lr: 1.0000e-05\n",
      "Epoch 89/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4644 - jaccard_coef: 0.4644 - accuracy: 0.6516\n",
      "Epoch 00089: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4644 - jaccard_coef: 0.4644 - accuracy: 0.6516 - val_loss: -0.4061 - val_jaccard_coef: 0.4061 - val_accuracy: 0.6204 - lr: 1.0000e-05\n",
      "Epoch 90/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4645 - jaccard_coef: 0.4645 - accuracy: 0.6513\n",
      "Epoch 00090: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4646 - jaccard_coef: 0.4646 - accuracy: 0.6514 - val_loss: -0.4086 - val_jaccard_coef: 0.4086 - val_accuracy: 0.6191 - lr: 1.0000e-05\n",
      "Epoch 91/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4649 - jaccard_coef: 0.4649 - accuracy: 0.6523\n",
      "Epoch 00091: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4649 - jaccard_coef: 0.4650 - accuracy: 0.6523 - val_loss: -0.4078 - val_jaccard_coef: 0.4078 - val_accuracy: 0.6210 - lr: 1.0000e-05\n",
      "Epoch 92/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4666 - jaccard_coef: 0.4666 - accuracy: 0.6533\n",
      "Epoch 00092: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4665 - jaccard_coef: 0.4665 - accuracy: 0.6533 - val_loss: -0.4069 - val_jaccard_coef: 0.4069 - val_accuracy: 0.6208 - lr: 1.0000e-05\n",
      "Epoch 93/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4663 - jaccard_coef: 0.4663 - accuracy: 0.6529\n",
      "Epoch 00093: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4663 - jaccard_coef: 0.4663 - accuracy: 0.6530 - val_loss: -0.4087 - val_jaccard_coef: 0.4087 - val_accuracy: 0.6196 - lr: 1.0000e-05\n",
      "Epoch 94/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4662 - jaccard_coef: 0.4662 - accuracy: 0.6527\n",
      "Epoch 00094: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4662 - jaccard_coef: 0.4662 - accuracy: 0.6527 - val_loss: -0.4077 - val_jaccard_coef: 0.4077 - val_accuracy: 0.6194 - lr: 1.0000e-05\n",
      "Epoch 95/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4672 - jaccard_coef: 0.4672 - accuracy: 0.6537\n",
      "Epoch 00095: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4673 - jaccard_coef: 0.4674 - accuracy: 0.6537 - val_loss: -0.4072 - val_jaccard_coef: 0.4072 - val_accuracy: 0.6197 - lr: 1.0000e-05\n",
      "Epoch 96/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4668 - jaccard_coef: 0.4668 - accuracy: 0.6530\n",
      "Epoch 00096: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4669 - jaccard_coef: 0.4669 - accuracy: 0.6531 - val_loss: -0.4069 - val_jaccard_coef: 0.4069 - val_accuracy: 0.6197 - lr: 1.0000e-05\n",
      "Epoch 97/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4661 - jaccard_coef: 0.4661 - accuracy: 0.6527\n",
      "Epoch 00097: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4661 - jaccard_coef: 0.4660 - accuracy: 0.6527 - val_loss: -0.4070 - val_jaccard_coef: 0.4070 - val_accuracy: 0.6211 - lr: 1.0000e-05\n",
      "Epoch 98/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4670 - jaccard_coef: 0.4670 - accuracy: 0.6540\n",
      "Epoch 00098: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4670 - jaccard_coef: 0.4670 - accuracy: 0.6540 - val_loss: -0.4051 - val_jaccard_coef: 0.4051 - val_accuracy: 0.6223 - lr: 1.0000e-05\n",
      "Epoch 99/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4651 - jaccard_coef: 0.4651 - accuracy: 0.6520\n",
      "Epoch 00099: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4651 - jaccard_coef: 0.4651 - accuracy: 0.6519 - val_loss: -0.4076 - val_jaccard_coef: 0.4076 - val_accuracy: 0.6209 - lr: 1.0000e-05\n",
      "Epoch 100/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: -0.4669 - jaccard_coef: 0.4669 - accuracy: 0.6534\n",
      "Epoch 00100: val_loss did not improve from -0.41524\n",
      "414/414 [==============================] - 17s 40ms/step - loss: -0.4670 - jaccard_coef: 0.4670 - accuracy: 0.6534 - val_loss: -0.4056 - val_jaccard_coef: 0.4056 - val_accuracy: 0.6219 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "results = model.fit(X_train, y_train, batch_size=32, epochs=100, callbacks=callbacks,\\\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "id": "h7gPqT9gxAmJ",
    "outputId": "fc5d6da0-6dc4-4bff-de50-db3a937ae3fb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.title(\"IoU Loss RGB Learning curve\")\n",
    "plt.plot(results.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(results.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot( np.argmin(results.history[\"val_loss\"]), np.min(results.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"IoU Loss\")\n",
    "plt.legend()\n",
    "#plt.savefig('output/IoU_RGB_LearningCurve.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PPoXuf2dxC3y",
    "outputId": "cc12cc4d-874f-41e4-8a65-7dbb74151611"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 1s 13ms/step - loss: -0.4056 - jaccard_coef: 0.4056 - accuracy: 0.6219\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-0.40555447340011597, 0.40555447340011597, 0.6219240427017212]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_valid,y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gOefHlYRUy6E"
   },
   "source": [
    "---\n",
    "\n",
    "Train a second model using BCE Loss rather than Jaccard (IoU) Loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "-QN8M2m5Ux2y",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "985e7537-57a9-4f82-f2cb-0104d567d874",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "414/414 [==============================] - ETA: 0s - loss: 0.6356 - jaccard_coef: 0.2282 - accuracy: 0.6267\n",
      "Epoch 00001: val_loss improved from inf to 0.63967, saving model to output/rgb_nutrient_deficiency_identifier_BCE.h5\n",
      "414/414 [==============================] - 55s 43ms/step - loss: 0.6356 - jaccard_coef: 0.2282 - accuracy: 0.6267 - val_loss: 0.6397 - val_jaccard_coef: 0.2401 - val_accuracy: 0.6147 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.6179 - jaccard_coef: 0.2398 - accuracy: 0.6424\n",
      "Epoch 00002: val_loss improved from 0.63967 to 0.63487, saving model to output/rgb_nutrient_deficiency_identifier_BCE.h5\n",
      "414/414 [==============================] - 17s 42ms/step - loss: 0.6179 - jaccard_coef: 0.2398 - accuracy: 0.6424 - val_loss: 0.6349 - val_jaccard_coef: 0.2665 - val_accuracy: 0.6182 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "414/414 [==============================] - ETA: 0s - loss: 0.6095 - jaccard_coef: 0.2483 - accuracy: 0.6482\n",
      "Epoch 00003: val_loss did not improve from 0.63487\n",
      "414/414 [==============================] - 17s 42ms/step - loss: 0.6095 - jaccard_coef: 0.2483 - accuracy: 0.6482 - val_loss: 0.6369 - val_jaccard_coef: 0.2387 - val_accuracy: 0.6260 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.6036 - jaccard_coef: 0.2537 - accuracy: 0.6527\n",
      "Epoch 00004: val_loss improved from 0.63487 to 0.61972, saving model to output/rgb_nutrient_deficiency_identifier_BCE.h5\n",
      "414/414 [==============================] - 17s 42ms/step - loss: 0.6036 - jaccard_coef: 0.2537 - accuracy: 0.6528 - val_loss: 0.6197 - val_jaccard_coef: 0.2719 - val_accuracy: 0.6384 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.5986 - jaccard_coef: 0.2580 - accuracy: 0.6562\n",
      "Epoch 00005: val_loss did not improve from 0.61972\n",
      "414/414 [==============================] - 17s 42ms/step - loss: 0.5986 - jaccard_coef: 0.2580 - accuracy: 0.6562 - val_loss: 0.6216 - val_jaccard_coef: 0.2734 - val_accuracy: 0.6362 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.5957 - jaccard_coef: 0.2609 - accuracy: 0.6579\n",
      "Epoch 00006: val_loss did not improve from 0.61972\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.5956 - jaccard_coef: 0.2610 - accuracy: 0.6579 - val_loss: 0.6470 - val_jaccard_coef: 0.2405 - val_accuracy: 0.6326 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "414/414 [==============================] - ETA: 0s - loss: 0.5920 - jaccard_coef: 0.2644 - accuracy: 0.6610\n",
      "Epoch 00007: val_loss improved from 0.61972 to 0.61946, saving model to output/rgb_nutrient_deficiency_identifier_BCE.h5\n",
      "414/414 [==============================] - 17s 42ms/step - loss: 0.5920 - jaccard_coef: 0.2644 - accuracy: 0.6610 - val_loss: 0.6195 - val_jaccard_coef: 0.2617 - val_accuracy: 0.6354 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.5893 - jaccard_coef: 0.2671 - accuracy: 0.6626\n",
      "Epoch 00008: val_loss improved from 0.61946 to 0.61365, saving model to output/rgb_nutrient_deficiency_identifier_BCE.h5\n",
      "414/414 [==============================] - 17s 42ms/step - loss: 0.5893 - jaccard_coef: 0.2671 - accuracy: 0.6626 - val_loss: 0.6136 - val_jaccard_coef: 0.2677 - val_accuracy: 0.6396 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.5856 - jaccard_coef: 0.2705 - accuracy: 0.6653\n",
      "Epoch 00009: val_loss did not improve from 0.61365\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.5855 - jaccard_coef: 0.2705 - accuracy: 0.6654 - val_loss: 0.6425 - val_jaccard_coef: 0.2316 - val_accuracy: 0.6215 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.5825 - jaccard_coef: 0.2733 - accuracy: 0.6676\n",
      "Epoch 00010: val_loss did not improve from 0.61365\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.5826 - jaccard_coef: 0.2733 - accuracy: 0.6675 - val_loss: 0.6228 - val_jaccard_coef: 0.2532 - val_accuracy: 0.6369 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.5792 - jaccard_coef: 0.2762 - accuracy: 0.6694\n",
      "Epoch 00011: val_loss did not improve from 0.61365\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.5792 - jaccard_coef: 0.2762 - accuracy: 0.6694 - val_loss: 0.6224 - val_jaccard_coef: 0.2638 - val_accuracy: 0.6389 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.5756 - jaccard_coef: 0.2801 - accuracy: 0.6721\n",
      "Epoch 00012: val_loss did not improve from 0.61365\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.5757 - jaccard_coef: 0.2800 - accuracy: 0.6721 - val_loss: 0.6506 - val_jaccard_coef: 0.2450 - val_accuracy: 0.6351 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.5739 - jaccard_coef: 0.2820 - accuracy: 0.6736\n",
      "Epoch 00013: val_loss did not improve from 0.61365\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.5739 - jaccard_coef: 0.2819 - accuracy: 0.6736 - val_loss: 0.6209 - val_jaccard_coef: 0.2590 - val_accuracy: 0.6373 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.5696 - jaccard_coef: 0.2861 - accuracy: 0.6767\n",
      "Epoch 00014: val_loss did not improve from 0.61365\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.5695 - jaccard_coef: 0.2860 - accuracy: 0.6768 - val_loss: 0.6287 - val_jaccard_coef: 0.2719 - val_accuracy: 0.6403 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.5679 - jaccard_coef: 0.2872 - accuracy: 0.6776\n",
      "Epoch 00015: val_loss did not improve from 0.61365\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.5680 - jaccard_coef: 0.2871 - accuracy: 0.6775 - val_loss: 0.6173 - val_jaccard_coef: 0.2826 - val_accuracy: 0.6470 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.5629 - jaccard_coef: 0.2922 - accuracy: 0.6810\n",
      "Epoch 00016: val_loss did not improve from 0.61365\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.5628 - jaccard_coef: 0.2922 - accuracy: 0.6810 - val_loss: 0.6245 - val_jaccard_coef: 0.2580 - val_accuracy: 0.6419 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.5606 - jaccard_coef: 0.2946 - accuracy: 0.6834\n",
      "Epoch 00017: val_loss improved from 0.61365 to 0.61357, saving model to output/rgb_nutrient_deficiency_identifier_BCE.h5\n",
      "414/414 [==============================] - 17s 42ms/step - loss: 0.5606 - jaccard_coef: 0.2947 - accuracy: 0.6834 - val_loss: 0.6136 - val_jaccard_coef: 0.2810 - val_accuracy: 0.6401 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.5606 - jaccard_coef: 0.2945 - accuracy: 0.6823\n",
      "Epoch 00018: val_loss did not improve from 0.61357\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.5607 - jaccard_coef: 0.2945 - accuracy: 0.6822 - val_loss: 0.6225 - val_jaccard_coef: 0.2905 - val_accuracy: 0.6428 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.5555 - jaccard_coef: 0.2998 - accuracy: 0.6868\n",
      "Epoch 00019: val_loss did not improve from 0.61357\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.5553 - jaccard_coef: 0.2999 - accuracy: 0.6869 - val_loss: 0.6194 - val_jaccard_coef: 0.2839 - val_accuracy: 0.6450 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.5518 - jaccard_coef: 0.3031 - accuracy: 0.6885\n",
      "Epoch 00020: val_loss did not improve from 0.61357\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.5517 - jaccard_coef: 0.3031 - accuracy: 0.6885 - val_loss: 0.6169 - val_jaccard_coef: 0.2695 - val_accuracy: 0.6446 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.5481 - jaccard_coef: 0.3067 - accuracy: 0.6920\n",
      "Epoch 00021: val_loss improved from 0.61357 to 0.60409, saving model to output/rgb_nutrient_deficiency_identifier_BCE.h5\n",
      "414/414 [==============================] - 17s 42ms/step - loss: 0.5481 - jaccard_coef: 0.3067 - accuracy: 0.6920 - val_loss: 0.6041 - val_jaccard_coef: 0.2876 - val_accuracy: 0.6497 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.5462 - jaccard_coef: 0.3088 - accuracy: 0.6925\n",
      "Epoch 00022: val_loss did not improve from 0.60409\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.5463 - jaccard_coef: 0.3088 - accuracy: 0.6924 - val_loss: 0.6131 - val_jaccard_coef: 0.2584 - val_accuracy: 0.6397 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.5437 - jaccard_coef: 0.3108 - accuracy: 0.6941\n",
      "Epoch 00023: val_loss did not improve from 0.60409\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.5437 - jaccard_coef: 0.3107 - accuracy: 0.6940 - val_loss: 0.6110 - val_jaccard_coef: 0.2755 - val_accuracy: 0.6441 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.5407 - jaccard_coef: 0.3140 - accuracy: 0.6962\n",
      "Epoch 00024: val_loss did not improve from 0.60409\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.5406 - jaccard_coef: 0.3140 - accuracy: 0.6962 - val_loss: 0.6159 - val_jaccard_coef: 0.2946 - val_accuracy: 0.6440 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.5374 - jaccard_coef: 0.3172 - accuracy: 0.6984\n",
      "Epoch 00025: val_loss did not improve from 0.60409\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.5375 - jaccard_coef: 0.3171 - accuracy: 0.6983 - val_loss: 0.6425 - val_jaccard_coef: 0.2503 - val_accuracy: 0.6421 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.5341 - jaccard_coef: 0.3205 - accuracy: 0.7010\n",
      "Epoch 00026: val_loss did not improve from 0.60409\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.5344 - jaccard_coef: 0.3205 - accuracy: 0.7008 - val_loss: 0.6215 - val_jaccard_coef: 0.2678 - val_accuracy: 0.6449 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.5314 - jaccard_coef: 0.3230 - accuracy: 0.7031\n",
      "Epoch 00027: val_loss did not improve from 0.60409\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.5314 - jaccard_coef: 0.3230 - accuracy: 0.7032 - val_loss: 0.6096 - val_jaccard_coef: 0.2833 - val_accuracy: 0.6461 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.5279 - jaccard_coef: 0.3264 - accuracy: 0.7052\n",
      "Epoch 00028: val_loss improved from 0.60409 to 0.60381, saving model to output/rgb_nutrient_deficiency_identifier_BCE.h5\n",
      "414/414 [==============================] - 17s 42ms/step - loss: 0.5280 - jaccard_coef: 0.3264 - accuracy: 0.7051 - val_loss: 0.6038 - val_jaccard_coef: 0.2880 - val_accuracy: 0.6504 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.5245 - jaccard_coef: 0.3300 - accuracy: 0.7070\n",
      "Epoch 00029: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.5247 - jaccard_coef: 0.3300 - accuracy: 0.7068 - val_loss: 0.6240 - val_jaccard_coef: 0.2772 - val_accuracy: 0.6453 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.5224 - jaccard_coef: 0.3321 - accuracy: 0.7077\n",
      "Epoch 00030: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.5224 - jaccard_coef: 0.3321 - accuracy: 0.7077 - val_loss: 0.6220 - val_jaccard_coef: 0.2744 - val_accuracy: 0.6465 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.5184 - jaccard_coef: 0.3360 - accuracy: 0.7108\n",
      "Epoch 00031: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.5184 - jaccard_coef: 0.3360 - accuracy: 0.7108 - val_loss: 0.6330 - val_jaccard_coef: 0.2625 - val_accuracy: 0.6395 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.5165 - jaccard_coef: 0.3380 - accuracy: 0.7132\n",
      "Epoch 00032: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.5165 - jaccard_coef: 0.3381 - accuracy: 0.7131 - val_loss: 0.6240 - val_jaccard_coef: 0.2815 - val_accuracy: 0.6501 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.5147 - jaccard_coef: 0.3398 - accuracy: 0.7132\n",
      "Epoch 00033: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.5147 - jaccard_coef: 0.3398 - accuracy: 0.7133 - val_loss: 0.6378 - val_jaccard_coef: 0.2698 - val_accuracy: 0.6465 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.5097 - jaccard_coef: 0.3451 - accuracy: 0.7162\n",
      "Epoch 00034: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.5097 - jaccard_coef: 0.3451 - accuracy: 0.7162 - val_loss: 0.6542 - val_jaccard_coef: 0.2746 - val_accuracy: 0.6452 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.5073 - jaccard_coef: 0.3469 - accuracy: 0.7186\n",
      "Epoch 00035: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.5073 - jaccard_coef: 0.3469 - accuracy: 0.7187 - val_loss: 0.6234 - val_jaccard_coef: 0.2985 - val_accuracy: 0.6453 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.5052 - jaccard_coef: 0.3493 - accuracy: 0.7195\n",
      "Epoch 00036: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.5052 - jaccard_coef: 0.3493 - accuracy: 0.7196 - val_loss: 0.6172 - val_jaccard_coef: 0.2815 - val_accuracy: 0.6494 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.5016 - jaccard_coef: 0.3537 - accuracy: 0.7223\n",
      "Epoch 00037: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.5018 - jaccard_coef: 0.3536 - accuracy: 0.7222 - val_loss: 0.6263 - val_jaccard_coef: 0.2815 - val_accuracy: 0.6439 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.5000 - jaccard_coef: 0.3547 - accuracy: 0.7243\n",
      "Epoch 00038: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.4999 - jaccard_coef: 0.3547 - accuracy: 0.7244 - val_loss: 0.6494 - val_jaccard_coef: 0.2574 - val_accuracy: 0.6448 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4969 - jaccard_coef: 0.3575 - accuracy: 0.7250\n",
      "Epoch 00039: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.4969 - jaccard_coef: 0.3576 - accuracy: 0.7250 - val_loss: 0.6451 - val_jaccard_coef: 0.2675 - val_accuracy: 0.6460 - lr: 0.0010\n",
      "Epoch 40/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4920 - jaccard_coef: 0.3630 - accuracy: 0.7289\n",
      "Epoch 00040: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.4921 - jaccard_coef: 0.3629 - accuracy: 0.7289 - val_loss: 0.6860 - val_jaccard_coef: 0.2560 - val_accuracy: 0.6392 - lr: 0.0010\n",
      "Epoch 41/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4902 - jaccard_coef: 0.3647 - accuracy: 0.7293\n",
      "Epoch 00041: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.4902 - jaccard_coef: 0.3646 - accuracy: 0.7293 - val_loss: 0.6274 - val_jaccard_coef: 0.2981 - val_accuracy: 0.6428 - lr: 0.0010\n",
      "Epoch 42/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4863 - jaccard_coef: 0.3690 - accuracy: 0.7321\n",
      "Epoch 00042: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.4862 - jaccard_coef: 0.3690 - accuracy: 0.7322 - val_loss: 0.6326 - val_jaccard_coef: 0.2798 - val_accuracy: 0.6459 - lr: 0.0010\n",
      "Epoch 43/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4833 - jaccard_coef: 0.3719 - accuracy: 0.7344\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.4832 - jaccard_coef: 0.3719 - accuracy: 0.7344 - val_loss: 0.6306 - val_jaccard_coef: 0.2837 - val_accuracy: 0.6510 - lr: 0.0010\n",
      "Epoch 44/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4610 - jaccard_coef: 0.3886 - accuracy: 0.7476\n",
      "Epoch 00044: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.4609 - jaccard_coef: 0.3887 - accuracy: 0.7476 - val_loss: 0.6180 - val_jaccard_coef: 0.3083 - val_accuracy: 0.6578 - lr: 1.0000e-04\n",
      "Epoch 45/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4555 - jaccard_coef: 0.3975 - accuracy: 0.7507\n",
      "Epoch 00045: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.4555 - jaccard_coef: 0.3975 - accuracy: 0.7507 - val_loss: 0.6228 - val_jaccard_coef: 0.3130 - val_accuracy: 0.6565 - lr: 1.0000e-04\n",
      "Epoch 46/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4546 - jaccard_coef: 0.4006 - accuracy: 0.7510\n",
      "Epoch 00046: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.4546 - jaccard_coef: 0.4005 - accuracy: 0.7510 - val_loss: 0.6198 - val_jaccard_coef: 0.3133 - val_accuracy: 0.6564 - lr: 1.0000e-04\n",
      "Epoch 47/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4536 - jaccard_coef: 0.4011 - accuracy: 0.7520\n",
      "Epoch 00047: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.4536 - jaccard_coef: 0.4012 - accuracy: 0.7519 - val_loss: 0.6265 - val_jaccard_coef: 0.3103 - val_accuracy: 0.6567 - lr: 1.0000e-04\n",
      "Epoch 48/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4486 - jaccard_coef: 0.4066 - accuracy: 0.7551\n",
      "Epoch 00048: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.4486 - jaccard_coef: 0.4065 - accuracy: 0.7551 - val_loss: 0.6364 - val_jaccard_coef: 0.3078 - val_accuracy: 0.6548 - lr: 1.0000e-04\n",
      "Epoch 49/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4498 - jaccard_coef: 0.4059 - accuracy: 0.7539\n",
      "Epoch 00049: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.4498 - jaccard_coef: 0.4058 - accuracy: 0.7539 - val_loss: 0.6249 - val_jaccard_coef: 0.3168 - val_accuracy: 0.6565 - lr: 1.0000e-04\n",
      "Epoch 50/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4498 - jaccard_coef: 0.4060 - accuracy: 0.7540\n",
      "Epoch 00050: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.4500 - jaccard_coef: 0.4059 - accuracy: 0.7539 - val_loss: 0.6346 - val_jaccard_coef: 0.3063 - val_accuracy: 0.6559 - lr: 1.0000e-04\n",
      "Epoch 51/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4473 - jaccard_coef: 0.4084 - accuracy: 0.7547\n",
      "Epoch 00051: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.4472 - jaccard_coef: 0.4085 - accuracy: 0.7548 - val_loss: 0.6259 - val_jaccard_coef: 0.3149 - val_accuracy: 0.6567 - lr: 1.0000e-04\n",
      "Epoch 52/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4468 - jaccard_coef: 0.4093 - accuracy: 0.7561\n",
      "Epoch 00052: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.4469 - jaccard_coef: 0.4093 - accuracy: 0.7560 - val_loss: 0.6335 - val_jaccard_coef: 0.3064 - val_accuracy: 0.6554 - lr: 1.0000e-04\n",
      "Epoch 53/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4460 - jaccard_coef: 0.4099 - accuracy: 0.7563\n",
      "Epoch 00053: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.4460 - jaccard_coef: 0.4099 - accuracy: 0.7563 - val_loss: 0.6286 - val_jaccard_coef: 0.3116 - val_accuracy: 0.6554 - lr: 1.0000e-04\n",
      "Epoch 54/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4460 - jaccard_coef: 0.4100 - accuracy: 0.7555\n",
      "Epoch 00054: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.4460 - jaccard_coef: 0.4101 - accuracy: 0.7554 - val_loss: 0.6377 - val_jaccard_coef: 0.3056 - val_accuracy: 0.6567 - lr: 1.0000e-04\n",
      "Epoch 55/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4442 - jaccard_coef: 0.4117 - accuracy: 0.7573\n",
      "Epoch 00055: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.4443 - jaccard_coef: 0.4117 - accuracy: 0.7572 - val_loss: 0.6341 - val_jaccard_coef: 0.3129 - val_accuracy: 0.6563 - lr: 1.0000e-04\n",
      "Epoch 56/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4439 - jaccard_coef: 0.4124 - accuracy: 0.7571\n",
      "Epoch 00056: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.4439 - jaccard_coef: 0.4124 - accuracy: 0.7571 - val_loss: 0.6350 - val_jaccard_coef: 0.3087 - val_accuracy: 0.6551 - lr: 1.0000e-04\n",
      "Epoch 57/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4435 - jaccard_coef: 0.4129 - accuracy: 0.7580\n",
      "Epoch 00057: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.4436 - jaccard_coef: 0.4129 - accuracy: 0.7580 - val_loss: 0.6293 - val_jaccard_coef: 0.3146 - val_accuracy: 0.6576 - lr: 1.0000e-04\n",
      "Epoch 58/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4416 - jaccard_coef: 0.4145 - accuracy: 0.7590\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.4417 - jaccard_coef: 0.4144 - accuracy: 0.7589 - val_loss: 0.6330 - val_jaccard_coef: 0.3146 - val_accuracy: 0.6564 - lr: 1.0000e-04\n",
      "Epoch 59/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4411 - jaccard_coef: 0.4155 - accuracy: 0.7594\n",
      "Epoch 00059: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.4410 - jaccard_coef: 0.4156 - accuracy: 0.7594 - val_loss: 0.6345 - val_jaccard_coef: 0.3150 - val_accuracy: 0.6571 - lr: 1.0000e-05\n",
      "Epoch 60/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4400 - jaccard_coef: 0.4163 - accuracy: 0.7603\n",
      "Epoch 00060: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.4400 - jaccard_coef: 0.4163 - accuracy: 0.7603 - val_loss: 0.6360 - val_jaccard_coef: 0.3128 - val_accuracy: 0.6566 - lr: 1.0000e-05\n",
      "Epoch 61/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4406 - jaccard_coef: 0.4155 - accuracy: 0.7595\n",
      "Epoch 00061: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.4408 - jaccard_coef: 0.4154 - accuracy: 0.7594 - val_loss: 0.6351 - val_jaccard_coef: 0.3140 - val_accuracy: 0.6568 - lr: 1.0000e-05\n",
      "Epoch 62/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4388 - jaccard_coef: 0.4165 - accuracy: 0.7603\n",
      "Epoch 00062: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.4389 - jaccard_coef: 0.4165 - accuracy: 0.7603 - val_loss: 0.6365 - val_jaccard_coef: 0.3125 - val_accuracy: 0.6570 - lr: 1.0000e-05\n",
      "Epoch 63/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4373 - jaccard_coef: 0.4181 - accuracy: 0.7612\n",
      "Epoch 00063: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.4371 - jaccard_coef: 0.4183 - accuracy: 0.7612 - val_loss: 0.6353 - val_jaccard_coef: 0.3146 - val_accuracy: 0.6569 - lr: 1.0000e-05\n",
      "Epoch 64/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4391 - jaccard_coef: 0.4172 - accuracy: 0.7602\n",
      "Epoch 00064: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.4390 - jaccard_coef: 0.4172 - accuracy: 0.7602 - val_loss: 0.6362 - val_jaccard_coef: 0.3131 - val_accuracy: 0.6567 - lr: 1.0000e-05\n",
      "Epoch 65/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4375 - jaccard_coef: 0.4184 - accuracy: 0.7615\n",
      "Epoch 00065: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.4375 - jaccard_coef: 0.4183 - accuracy: 0.7615 - val_loss: 0.6365 - val_jaccard_coef: 0.3139 - val_accuracy: 0.6574 - lr: 1.0000e-05\n",
      "Epoch 66/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4382 - jaccard_coef: 0.4179 - accuracy: 0.7607\n",
      "Epoch 00066: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.4382 - jaccard_coef: 0.4180 - accuracy: 0.7607 - val_loss: 0.6361 - val_jaccard_coef: 0.3132 - val_accuracy: 0.6567 - lr: 1.0000e-05\n",
      "Epoch 67/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4380 - jaccard_coef: 0.4187 - accuracy: 0.7613\n",
      "Epoch 00067: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.4380 - jaccard_coef: 0.4187 - accuracy: 0.7614 - val_loss: 0.6361 - val_jaccard_coef: 0.3143 - val_accuracy: 0.6570 - lr: 1.0000e-05\n",
      "Epoch 68/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4378 - jaccard_coef: 0.4182 - accuracy: 0.7609\n",
      "Epoch 00068: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.4380 - jaccard_coef: 0.4182 - accuracy: 0.7608 - val_loss: 0.6358 - val_jaccard_coef: 0.3140 - val_accuracy: 0.6572 - lr: 1.0000e-05\n",
      "Epoch 69/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4380 - jaccard_coef: 0.4187 - accuracy: 0.7612\n",
      "Epoch 00069: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.4380 - jaccard_coef: 0.4186 - accuracy: 0.7612 - val_loss: 0.6354 - val_jaccard_coef: 0.3165 - val_accuracy: 0.6572 - lr: 1.0000e-05\n",
      "Epoch 70/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4383 - jaccard_coef: 0.4183 - accuracy: 0.7610\n",
      "Epoch 00070: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.4383 - jaccard_coef: 0.4183 - accuracy: 0.7609 - val_loss: 0.6361 - val_jaccard_coef: 0.3148 - val_accuracy: 0.6570 - lr: 1.0000e-05\n",
      "Epoch 71/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4381 - jaccard_coef: 0.4184 - accuracy: 0.7606\n",
      "Epoch 00071: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.4382 - jaccard_coef: 0.4182 - accuracy: 0.7605 - val_loss: 0.6361 - val_jaccard_coef: 0.3135 - val_accuracy: 0.6564 - lr: 1.0000e-05\n",
      "Epoch 72/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4386 - jaccard_coef: 0.4181 - accuracy: 0.7605\n",
      "Epoch 00072: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.4386 - jaccard_coef: 0.4181 - accuracy: 0.7605 - val_loss: 0.6355 - val_jaccard_coef: 0.3164 - val_accuracy: 0.6571 - lr: 1.0000e-05\n",
      "Epoch 73/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4382 - jaccard_coef: 0.4182 - accuracy: 0.7609\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.4382 - jaccard_coef: 0.4182 - accuracy: 0.7609 - val_loss: 0.6358 - val_jaccard_coef: 0.3127 - val_accuracy: 0.6567 - lr: 1.0000e-05\n",
      "Epoch 74/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4386 - jaccard_coef: 0.4179 - accuracy: 0.7607\n",
      "Epoch 00074: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.4386 - jaccard_coef: 0.4179 - accuracy: 0.7607 - val_loss: 0.6370 - val_jaccard_coef: 0.3134 - val_accuracy: 0.6567 - lr: 1.0000e-05\n",
      "Epoch 75/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4383 - jaccard_coef: 0.4182 - accuracy: 0.7611\n",
      "Epoch 00075: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.4383 - jaccard_coef: 0.4181 - accuracy: 0.7611 - val_loss: 0.6372 - val_jaccard_coef: 0.3124 - val_accuracy: 0.6571 - lr: 1.0000e-05\n",
      "Epoch 76/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4369 - jaccard_coef: 0.4192 - accuracy: 0.7618\n",
      "Epoch 00076: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.4369 - jaccard_coef: 0.4192 - accuracy: 0.7617 - val_loss: 0.6366 - val_jaccard_coef: 0.3152 - val_accuracy: 0.6571 - lr: 1.0000e-05\n",
      "Epoch 77/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4383 - jaccard_coef: 0.4187 - accuracy: 0.7605\n",
      "Epoch 00077: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 42ms/step - loss: 0.4383 - jaccard_coef: 0.4187 - accuracy: 0.7605 - val_loss: 0.6375 - val_jaccard_coef: 0.3135 - val_accuracy: 0.6568 - lr: 1.0000e-05\n",
      "Epoch 78/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4363 - jaccard_coef: 0.4198 - accuracy: 0.7622\n",
      "Epoch 00078: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 42ms/step - loss: 0.4365 - jaccard_coef: 0.4197 - accuracy: 0.7622 - val_loss: 0.6370 - val_jaccard_coef: 0.3157 - val_accuracy: 0.6569 - lr: 1.0000e-05\n",
      "Epoch 79/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4396 - jaccard_coef: 0.4178 - accuracy: 0.7599\n",
      "Epoch 00079: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 42ms/step - loss: 0.4396 - jaccard_coef: 0.4177 - accuracy: 0.7599 - val_loss: 0.6371 - val_jaccard_coef: 0.3159 - val_accuracy: 0.6569 - lr: 1.0000e-05\n",
      "Epoch 80/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4394 - jaccard_coef: 0.4178 - accuracy: 0.7598\n",
      "Epoch 00080: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 42ms/step - loss: 0.4393 - jaccard_coef: 0.4180 - accuracy: 0.7599 - val_loss: 0.6383 - val_jaccard_coef: 0.3158 - val_accuracy: 0.6569 - lr: 1.0000e-05\n",
      "Epoch 81/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4393 - jaccard_coef: 0.4176 - accuracy: 0.7602\n",
      "Epoch 00081: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 42ms/step - loss: 0.4393 - jaccard_coef: 0.4177 - accuracy: 0.7602 - val_loss: 0.6380 - val_jaccard_coef: 0.3141 - val_accuracy: 0.6569 - lr: 1.0000e-05\n",
      "Epoch 82/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4383 - jaccard_coef: 0.4186 - accuracy: 0.7609\n",
      "Epoch 00082: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 42ms/step - loss: 0.4384 - jaccard_coef: 0.4184 - accuracy: 0.7608 - val_loss: 0.6379 - val_jaccard_coef: 0.3137 - val_accuracy: 0.6567 - lr: 1.0000e-05\n",
      "Epoch 83/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4362 - jaccard_coef: 0.4198 - accuracy: 0.7624\n",
      "Epoch 00083: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 42ms/step - loss: 0.4362 - jaccard_coef: 0.4198 - accuracy: 0.7624 - val_loss: 0.6352 - val_jaccard_coef: 0.3140 - val_accuracy: 0.6569 - lr: 1.0000e-05\n",
      "Epoch 84/100\n",
      "414/414 [==============================] - ETA: 0s - loss: 0.4369 - jaccard_coef: 0.4198 - accuracy: 0.7617\n",
      "Epoch 00084: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.4369 - jaccard_coef: 0.4198 - accuracy: 0.7617 - val_loss: 0.6366 - val_jaccard_coef: 0.3147 - val_accuracy: 0.6569 - lr: 1.0000e-05\n",
      "Epoch 85/100\n",
      "414/414 [==============================] - ETA: 0s - loss: 0.4371 - jaccard_coef: 0.4194 - accuracy: 0.7614\n",
      "Epoch 00085: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.4371 - jaccard_coef: 0.4194 - accuracy: 0.7614 - val_loss: 0.6364 - val_jaccard_coef: 0.3164 - val_accuracy: 0.6569 - lr: 1.0000e-05\n",
      "Epoch 86/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4381 - jaccard_coef: 0.4189 - accuracy: 0.7609\n",
      "Epoch 00086: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.4381 - jaccard_coef: 0.4190 - accuracy: 0.7609 - val_loss: 0.6367 - val_jaccard_coef: 0.3137 - val_accuracy: 0.6568 - lr: 1.0000e-05\n",
      "Epoch 87/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4382 - jaccard_coef: 0.4185 - accuracy: 0.7606\n",
      "Epoch 00087: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.4383 - jaccard_coef: 0.4184 - accuracy: 0.7606 - val_loss: 0.6377 - val_jaccard_coef: 0.3137 - val_accuracy: 0.6568 - lr: 1.0000e-05\n",
      "Epoch 88/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4378 - jaccard_coef: 0.4189 - accuracy: 0.7613\n",
      "Epoch 00088: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.4377 - jaccard_coef: 0.4189 - accuracy: 0.7614 - val_loss: 0.6369 - val_jaccard_coef: 0.3140 - val_accuracy: 0.6569 - lr: 1.0000e-05\n",
      "Epoch 89/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4372 - jaccard_coef: 0.4193 - accuracy: 0.7621\n",
      "Epoch 00089: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.4371 - jaccard_coef: 0.4194 - accuracy: 0.7622 - val_loss: 0.6346 - val_jaccard_coef: 0.3150 - val_accuracy: 0.6569 - lr: 1.0000e-05\n",
      "Epoch 90/100\n",
      "414/414 [==============================] - ETA: 0s - loss: 0.4363 - jaccard_coef: 0.4202 - accuracy: 0.7622\n",
      "Epoch 00090: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.4363 - jaccard_coef: 0.4202 - accuracy: 0.7622 - val_loss: 0.6374 - val_jaccard_coef: 0.3147 - val_accuracy: 0.6567 - lr: 1.0000e-05\n",
      "Epoch 91/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4361 - jaccard_coef: 0.4199 - accuracy: 0.7622\n",
      "Epoch 00091: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.4362 - jaccard_coef: 0.4199 - accuracy: 0.7622 - val_loss: 0.6392 - val_jaccard_coef: 0.3121 - val_accuracy: 0.6567 - lr: 1.0000e-05\n",
      "Epoch 92/100\n",
      "414/414 [==============================] - ETA: 0s - loss: 0.4352 - jaccard_coef: 0.4207 - accuracy: 0.7623\n",
      "Epoch 00092: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 42ms/step - loss: 0.4352 - jaccard_coef: 0.4207 - accuracy: 0.7623 - val_loss: 0.6380 - val_jaccard_coef: 0.3137 - val_accuracy: 0.6572 - lr: 1.0000e-05\n",
      "Epoch 93/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4377 - jaccard_coef: 0.4198 - accuracy: 0.7609\n",
      "Epoch 00093: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.4376 - jaccard_coef: 0.4198 - accuracy: 0.7609 - val_loss: 0.6375 - val_jaccard_coef: 0.3151 - val_accuracy: 0.6568 - lr: 1.0000e-05\n",
      "Epoch 94/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4361 - jaccard_coef: 0.4206 - accuracy: 0.7623\n",
      "Epoch 00094: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.4362 - jaccard_coef: 0.4206 - accuracy: 0.7623 - val_loss: 0.6380 - val_jaccard_coef: 0.3116 - val_accuracy: 0.6570 - lr: 1.0000e-05\n",
      "Epoch 95/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4351 - jaccard_coef: 0.4212 - accuracy: 0.7630\n",
      "Epoch 00095: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 42ms/step - loss: 0.4350 - jaccard_coef: 0.4212 - accuracy: 0.7631 - val_loss: 0.6371 - val_jaccard_coef: 0.3129 - val_accuracy: 0.6572 - lr: 1.0000e-05\n",
      "Epoch 96/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4338 - jaccard_coef: 0.4224 - accuracy: 0.7634\n",
      "Epoch 00096: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.4339 - jaccard_coef: 0.4225 - accuracy: 0.7634 - val_loss: 0.6370 - val_jaccard_coef: 0.3149 - val_accuracy: 0.6572 - lr: 1.0000e-05\n",
      "Epoch 97/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4370 - jaccard_coef: 0.4207 - accuracy: 0.7621\n",
      "Epoch 00097: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.4369 - jaccard_coef: 0.4209 - accuracy: 0.7622 - val_loss: 0.6391 - val_jaccard_coef: 0.3143 - val_accuracy: 0.6568 - lr: 1.0000e-05\n",
      "Epoch 98/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4357 - jaccard_coef: 0.4214 - accuracy: 0.7626\n",
      "Epoch 00098: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 42ms/step - loss: 0.4356 - jaccard_coef: 0.4215 - accuracy: 0.7626 - val_loss: 0.6382 - val_jaccard_coef: 0.3136 - val_accuracy: 0.6567 - lr: 1.0000e-05\n",
      "Epoch 99/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4364 - jaccard_coef: 0.4209 - accuracy: 0.7625\n",
      "Epoch 00099: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.4364 - jaccard_coef: 0.4209 - accuracy: 0.7624 - val_loss: 0.6375 - val_jaccard_coef: 0.3156 - val_accuracy: 0.6568 - lr: 1.0000e-05\n",
      "Epoch 100/100\n",
      "413/414 [============================>.] - ETA: 0s - loss: 0.4376 - jaccard_coef: 0.4201 - accuracy: 0.7617\n",
      "Epoch 00100: val_loss did not improve from 0.60381\n",
      "414/414 [==============================] - 17s 41ms/step - loss: 0.4377 - jaccard_coef: 0.4201 - accuracy: 0.7616 - val_loss: 0.6367 - val_jaccard_coef: 0.3155 - val_accuracy: 0.6571 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "input_img = Input((im_height, im_width, input_channels), name='img')\n",
    "bce_model = get_unet(input_img, n_filters=16, dropout=0.10, batchnorm=True)\n",
    "bce_model.compile(optimizer=Adam(), loss=['binary_crossentropy'], metrics=[jaccard_coef,\"accuracy\"])\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(factor=0.1, patience=15, min_lr=0.00001, verbose=1),\n",
    "    ModelCheckpoint('output/rgb_nutrient_deficiency_identifier_BCE.h5', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "]\n",
    "\n",
    "bce_results = bce_model.fit(X_train, y_train, batch_size=32, epochs=100, callbacks=callbacks,\\\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "id": "26G4nykFakRg",
    "outputId": "d879aedd-2548-445e-94d9-659299df3e4c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.title(\"Binary Crossentropy Loss RGB Learning curve\")\n",
    "plt.plot(bce_results.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(bce_results.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot( np.argmin(bce_results.history[\"val_loss\"]), np.min(bce_results.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"BCE loss\")\n",
    "plt.legend()\n",
    "#plt.savefig('output/BCE_RGB_LearningCurve.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1oh9foAugpR9",
    "outputId": "efe51af6-de28-4efe-8490-4d1fece7d7ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All changes made in this colab session should now be visible in Drive.\n"
     ]
    }
   ],
   "source": [
    "drive.flush_and_unmount()\n",
    "print('All changes made in this colab session should now be visible in Drive.')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "UNET_Agricultural_Nutrient_Deficiency_Finder.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
